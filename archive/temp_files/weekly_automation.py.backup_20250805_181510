#!/usr/bin/env python3
"""
ã‚¸ãƒ æ··é›‘çŠ¶æ³ å®Œå…¨è‡ªå‹•åŒ–ã‚·ã‚¹ãƒ†ãƒ ï¼ˆé€±æ¬¡å®Ÿè¡Œå¯¾å¿œç‰ˆï¼‰
- ãƒ¡ãƒ¢ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°æ©Ÿèƒ½ä»˜ã
- è‡ªå‹•å®Ÿè¡Œå¯¾å¿œ
- å®‰å…¨ãªãƒ‡ãƒ¼ã‚¿å‡¦ç†
"""

import subprocess
import re
import csv
import os
import shutil
import json
from datetime import datetime, timedelta
from collections import defaultdict
import logging


class GymAnalysisAutomation:
    def __init__(self):
        self.project_dir = "/Users/i_kawano/Documents/training_waitnum_analysis"
        self.csv_file = os.path.join(self.project_dir, "fit_place24_data.csv")
        self.backup_dir = os.path.join(self.project_dir, "backups")
        self.log_file = os.path.join(self.project_dir, "automation.log")
        self.memo_name = "ğŸ“¸Shortcutã§FIT PLACE24ã®æ··é›‘çŠ¶æ³OCR"
        # å®Ÿéš›ã®ãƒ¡ãƒ¢åã«ã¯URLãŒå«ã¾ã‚Œã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ãŸã‚ã€éƒ¨åˆ†ä¸€è‡´ã§æ¤œç´¢

        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã¨ãƒ­ã‚°ã®åˆæœŸåŒ–
        self._setup_directories()
        self._setup_logging()

    def _setup_directories(self):
        """å¿…è¦ãªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ"""
        os.makedirs(self.backup_dir, exist_ok=True)

    def _setup_logging(self):
        """ãƒ­ã‚°è¨­å®š"""
        logging.basicConfig(
            level=logging.INFO,
            format="%(asctime)s - %(levelname)s - %(message)s",
            handlers=[
                logging.FileHandler(self.log_file, encoding="utf-8"),
                logging.StreamHandler(),
            ],
        )
        self.logger = logging.getLogger(__name__)

    def get_memo_content(self):
        """ãƒ¡ãƒ¢ã‚¢ãƒ—ãƒªã‹ã‚‰å†…å®¹ã‚’å–å¾—"""
        # è¤‡æ•°ã®æ–¹æ³•ã§ãƒ¡ãƒ¢ã‚’æ¤œç´¢
        search_methods = [
            # æ–¹æ³•1: ç‰¹å®šã®ãƒ¡ãƒ¢åã§æ¤œç´¢
            '''
            tell application "Notes"
                try
                    set targetNote to first note whose name contains "ãƒ•ã‚£ãƒƒãƒˆ"
                    return body of targetNote
                on error
                    return ""
                end try
            end tell
            ''',
            # æ–¹æ³•2: æ··é›‘çŠ¶æ³ãƒ‡ãƒ¼ã‚¿ã‚’å«ã‚€ãƒ¡ãƒ¢ã‚’æ¤œç´¢
            '''
            tell application "Notes"
                set allNotes to every note
                repeat with aNote in allNotes
                    set noteBody to body of aNote
                    if noteBody contains "æ··é›œçŠ¶æ³" or noteBody contains "æ··é›‘çŠ¶æ³" then
                        return noteBody
                    end if
                end repeat
                return ""
            end tell
            ''',
            # æ–¹æ³•3: æœ€æ–°ã®ãƒ¡ãƒ¢ï¼ˆæœ€å¾Œã®æ‰‹æ®µï¼‰
            '''
            tell application "Notes"
                set noteContent to body of note 1
                return noteContent
            end tell
            '''
        ]

        for i, script in enumerate(search_methods, 1):
            try:
                self.logger.info(f"ãƒ¡ãƒ¢æ¤œç´¢æ–¹æ³• {i} ã‚’è©¦è¡Œä¸­...")
                result = subprocess.run(
                    ["osascript", "-e", script],
                    capture_output=True,
                    text=True,
                    encoding="utf-8",
                    timeout=15
                )
                
                if result.returncode == 0 and result.stdout.strip():
                    content = result.stdout.strip()
                    # æ··é›‘çŠ¶æ³ãƒ‡ãƒ¼ã‚¿ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
                    if "æ··é›œçŠ¶æ³" in content or "æ··é›‘çŠ¶æ³" in content:
                        self.logger.info(f"âœ… æ–¹æ³• {i} ã§æ··é›‘çŠ¶æ³ãƒ‡ãƒ¼ã‚¿ã‚’å«ã‚€ãƒ¡ãƒ¢ã‚’ç™ºè¦‹")
                        return content
                    elif i == len(search_methods):  # æœ€å¾Œã®æ–¹æ³•ã®å ´åˆã¯ãã®ã¾ã¾è¿”ã™
                        self.logger.info(f"âš ï¸ æ–¹æ³• {i} ã§ãƒ¡ãƒ¢ã‚’å–å¾—ï¼ˆæ··é›‘çŠ¶æ³ãƒ‡ãƒ¼ã‚¿ãªã—ï¼‰")
                        return content
                        
            except Exception as e:
                self.logger.warning(f"ãƒ¡ãƒ¢æ¤œç´¢æ–¹æ³• {i} ã§ã‚¨ãƒ©ãƒ¼: {e}")
                continue
        
        self.logger.error("ã™ã¹ã¦ã®ãƒ¡ãƒ¢æ¤œç´¢æ–¹æ³•ãŒå¤±æ•—ã—ã¾ã—ãŸ")
        return None

    def backup_memo_content(self, memo_content):
        """ãƒ¡ãƒ¢å†…å®¹ã‚’ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_file = os.path.join(self.backup_dir, f"memo_backup_{timestamp}.txt")

        try:
            with open(backup_file, "w", encoding="utf-8") as f:
                f.write(memo_content)
            self.logger.info(f"ãƒ¡ãƒ¢ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ: {backup_file}")
            return backup_file
        except Exception as e:
            self.logger.error(f"ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼: {e}")
            return None

    def extract_gym_data(self, memo_content):
        """ãƒ¡ãƒ¢ã‹ã‚‰æ··é›‘çŠ¶æ³ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºãƒ»æ§‹é€ åŒ–"""
        # HTMLã‚¿ã‚°ã‚’é™¤å»ã—ã¦ã‚¯ãƒªãƒ¼ãƒ³ãªãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›
        clean_content = re.sub(r"<[^>]*>", "", memo_content)
        
        # æ··é›‘çŠ¶æ³ãƒ‡ãƒ¼ã‚¿ã‚’æ­£è¦è¡¨ç¾ã§æŠ½å‡º
        gym_data = []
        processed_patterns = []  # å‡¦ç†ã—ãŸãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è¨˜éŒ²
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³: "æ··é›œçŠ¶æ³ 15äºº ã‚„ã‚„ç©ºã„ã¦ã„ã¾ã™ 08:30æ™‚ç‚¹" or "æ··é›œçŠ¶æ³ 15äºº ã‚„ã‚„ç©ºã„ã¦ã„ã¾ã™ 08:30æ™‚ç‚¹ 08/04"
        pattern = r"æ··[é›œé›‘]çŠ¶æ³\s*(\d+)äºº\s*([^\d]*?)\s*(\d{1,2}):(\d{2})æ™‚ç‚¹(?:\s*(\d{2}/\d{2}))?"
        
        matches = re.finditer(pattern, clean_content)
        match_count = 0
        
        for match in matches:
            match_count += 1
            try:
                count = int(match.group(1))
                status_text = match.group(2).strip()
                hour = int(match.group(3))
                minute = int(match.group(4))
                date_part = match.group(5) if match.group(5) else ""
                
                # ãƒãƒƒãƒã—ãŸå…¨ä½“ãƒ†ã‚­ã‚¹ãƒˆã‚’è¨˜éŒ²ï¼ˆå‰Šé™¤ç”¨ï¼‰
                matched_text = match.group(0)
                processed_patterns.append(matched_text)
                
                # æ—¥ä»˜ã®è¨­å®š
                current_date = datetime.now()
                if date_part:
                    try:
                        # MM/DD å½¢å¼ã®å ´åˆ
                        month, day = map(int, date_part.split('/'))
                        current_date = datetime(current_date.year, month, day)
                    except:
                        # è§£æå¤±æ•—æ™‚ã¯ä»Šæ—¥ã®æ—¥ä»˜ã‚’ä½¿ç”¨
                        pass
                
                # æ··é›‘åº¦ã‚’åˆ¤å®š
                if "ç©ºã„ã¦ã„ã¾ã™" in status_text and "ã‚„ã‚„" not in status_text:
                    status_code = 5
                    status_label = "ç©ºã„ã¦ã„ã¾ã™ï¼ˆ~10äººï¼‰"
                    status_min, status_max = 0, 10
                elif "ã‚„ã‚„ç©ºã„ã¦ã„ã¾ã™" in status_text:
                    status_code = 4
                    status_label = "ã‚„ã‚„ç©ºã„ã¦ã„ã¾ã™ï¼ˆ~20äººï¼‰"
                    status_min, status_max = 11, 20
                elif "ã‚„ã‚„æ··ã‚“ã§ã„ã¾ã™" in status_text:
                    status_code = 3
                    status_label = "å°‘ã—æ··ã‚“ã§ã„ã¾ã™ï¼ˆ~30äººï¼‰"
                    status_min, status_max = 21, 30
                elif "å°‘ã—æ··ã‚“ã§ã„ã¾ã™" in status_text:
                    status_code = 3
                    status_label = "å°‘ã—æ··ã‚“ã§ã„ã¾ã™ï¼ˆ~30äººï¼‰"
                    status_min, status_max = 21, 30
                elif "æ··ã‚“ã§ã„ã¾ã™" in status_text:
                    status_code = 2
                    status_label = "æ··ã‚“ã§ã„ã¾ã™ï¼ˆ~40äººï¼‰"
                    status_min, status_max = 31, 40
                else:
                    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼ˆäººæ•°ã‹ã‚‰æ¨å®šï¼‰
                    if count <= 10:
                        status_code = 5
                        status_label = "ç©ºã„ã¦ã„ã¾ã™ï¼ˆ~10äººï¼‰"
                        status_min, status_max = 0, 10
                    elif count <= 20:
                        status_code = 4
                        status_label = "ã‚„ã‚„ç©ºã„ã¦ã„ã¾ã™ï¼ˆ~20äººï¼‰"
                        status_min, status_max = 11, 20
                    elif count <= 30:
                        status_code = 3
                        status_label = "å°‘ã—æ··ã‚“ã§ã„ã¾ã™ï¼ˆ~30äººï¼‰"
                        status_min, status_max = 21, 30
                    else:
                        status_code = 2
                        status_label = "æ··ã‚“ã§ã„ã¾ã™ï¼ˆ~40äººï¼‰"
                        status_min, status_max = 31, 40

                # æ—¥æ™‚ã‚’è¨­å®š
                target_date = current_date.date()
                datetime_str = f"{target_date} {hour:02d}:{minute:02d}:00"
                date_str = str(target_date)
                time_str = f"{hour:02d}:{minute:02d}"
                weekday = target_date.strftime("%A")

                # ç”Ÿãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
                raw_text = f"æ··é›œçŠ¶æ³ {count}äºº {status_text} {hour}:{minute:02d}æ™‚ç‚¹"

                gym_data.append(
                    {
                        "datetime": datetime_str,
                        "date": date_str,
                        "time": time_str,
                        "hour": hour,
                        "weekday": weekday,
                        "count": count,
                        "status_label": status_label,
                        "status_code": status_code,
                        "status_min": status_min,
                        "status_max": status_max,
                        "raw_text": raw_text,
                        "original_match": matched_text,  # å…ƒã®ãƒãƒƒãƒãƒ†ã‚­ã‚¹ãƒˆã‚’ä¿å­˜
                    }
                )
                
                self.logger.info(f"ãƒ‡ãƒ¼ã‚¿æŠ½å‡º: {count}äºº {status_text} {hour}:{minute:02d}æ™‚ç‚¹")
                
            except Exception as e:
                self.logger.warning(f"ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}, match: {match}")
                continue
        
        self.logger.info(f"æ­£è¦è¡¨ç¾ã§æŠ½å‡ºã—ãŸãƒãƒƒãƒæ•°: {match_count}")
        return gym_data, processed_patterns

    def get_existing_csv_data(self):
        """æ—¢å­˜ã®CSVãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—"""
        existing_data = []
        existing_datetimes = set()

        if os.path.exists(self.csv_file):
            try:
                with open(self.csv_file, "r", encoding="utf-8") as f:
                    reader = csv.DictReader(f)
                    for row in reader:
                        existing_data.append(row)
                        existing_datetimes.add(row["datetime"])
            except Exception as e:
                self.logger.error(f"CSVèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")

        return existing_data, existing_datetimes

    def update_csv(self, new_gym_data):
        """CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›´æ–°"""
        existing_data, existing_datetimes = self.get_existing_csv_data()

        # æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã®ã¿ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        new_data = []
        for data in new_gym_data:
            if data["datetime"] not in existing_datetimes:
                new_data.append(data)

        # æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
        if new_data:
            # å…¨ãƒ‡ãƒ¼ã‚¿ã‚’çµ±åˆ
            all_data = existing_data + new_data

            # æ—¥æ™‚é †ã«ã‚½ãƒ¼ãƒˆ
            all_data.sort(key=lambda x: x["datetime"])

            # CSVãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãè¾¼ã¿
            try:
                with open(self.csv_file, "w", encoding="utf-8", newline="") as f:
                    fieldnames = [
                        "datetime",
                        "date",
                        "time",
                        "hour",
                        "weekday",
                        "count",
                        "status_label",
                        "status_code",
                        "status_min",
                        "status_max",
                        "raw_text",
                    ]
                    writer = csv.DictWriter(f, fieldnames=fieldnames)
                    writer.writeheader()
                    writer.writerows(all_data)

                self.logger.info(
                    f"CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›´æ–°: {len(new_data)}ä»¶è¿½åŠ , ç·æ•°{len(all_data)}ä»¶"
                )
                return len(new_data), len(all_data)
            except Exception as e:
                self.logger.error(f"CSVæ›¸ãè¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
                return 0, len(existing_data)
        else:
            return 0, len(existing_data)

    def clean_processed_patterns_from_memo(self, memo_content, processed_patterns):
        """å‡¦ç†æ¸ˆã¿ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ãƒ¡ãƒ¢ã‹ã‚‰å‰Šé™¤"""
        if not processed_patterns:
            self.logger.info("å‡¦ç†ã•ã‚ŒãŸãƒ‘ã‚¿ãƒ¼ãƒ³ãŒã‚ã‚Šã¾ã›ã‚“")
            return memo_content
        
        # HTMLã‚¿ã‚°ã‚’é™¤å»ã—ãŸã‚¯ãƒªãƒ¼ãƒ³ãªå†…å®¹
        clean_content = re.sub(r"<[^>]*>", "", memo_content)
        
        # å‡¦ç†ã•ã‚ŒãŸãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å‰Šé™¤
        updated_content = clean_content
        removed_count = 0
        
        for pattern in processed_patterns:
            if pattern in updated_content:
                updated_content = updated_content.replace(pattern, "")
                removed_count += 1
                self.logger.info(f"ãƒ‘ã‚¿ãƒ¼ãƒ³å‰Šé™¤: {pattern}")
        
        # ä½™åˆ†ãªç©ºç™½ã‚„æ”¹è¡Œã‚’æ•´ç†
        lines = updated_content.split('\n')
        cleaned_lines = []
        
        for line in lines:
            # ç©ºè¡Œã‚„ç©ºç™½ã®ã¿ã®è¡Œã‚’ã‚¹ã‚­ãƒƒãƒ—ã€è¤‡æ•°ã®ã‚¹ãƒšãƒ¼ã‚¹ã‚’æ•´ç†
            cleaned_line = ' '.join(line.split())  # è¤‡æ•°ã‚¹ãƒšãƒ¼ã‚¹ã‚’1ã¤ã«
            if cleaned_line:
                cleaned_lines.append(cleaned_line)
        
        # HTMLã‚¿ã‚°ã‚’å¾©å…ƒï¼ˆåŸºæœ¬æ§‹é€ ã®ã¿ï¼‰
        if cleaned_lines:
            # ã‚¿ã‚¤ãƒˆãƒ«è¡ŒãŒã‚ã‚Œã°ä¿æŒ
            title_lines = [line for line in cleaned_lines if "ãƒ•ã‚£ãƒƒãƒˆãƒ—ãƒ¬ã‚¤ã‚¹24" in line and "æ··é›œçŠ¶æ³" not in line]
            data_lines = [line for line in cleaned_lines if "ãƒ•ã‚£ãƒƒãƒˆãƒ—ãƒ¬ã‚¤ã‚¹24" not in line or "æ··é›œçŠ¶æ³" in line]
            
            # æ§‹é€ ã‚’å†æ§‹ç¯‰
            if title_lines:
                result_content = f"<div>{title_lines[0]}<br></div>"
                if data_lines:
                    # ãƒ‡ãƒ¼ã‚¿è¡ŒãŒã‚ã‚Œã°è¿½åŠ ï¼ˆ1è¡Œã«ã¾ã¨ã‚ã‚‹ï¼‰
                    data_content = ' '.join(data_lines)
                    if data_content.strip():
                        result_content += f"\n<div>{data_content}<br></div>"
            else:
                if data_lines:
                    data_content = ' '.join(data_lines)
                    result_content = f"<div>ãƒ•ã‚£ãƒƒãƒˆãƒ—ãƒ¬ã‚¤ã‚¹24ç·´é¦¬æ—©å®®<br></div>\n<div>{data_content}<br></div>"
                else:
                    result_content = "<div>ãƒ•ã‚£ãƒƒãƒˆãƒ—ãƒ¬ã‚¤ã‚¹24ç·´é¦¬æ—©å®®<br></div>"
        else:
            # ã™ã¹ã¦å‰Šé™¤ã•ã‚ŒãŸå ´åˆã€åŸºæœ¬æ§‹é€ ã®ã¿æ®‹ã™
            result_content = "<div>ãƒ•ã‚£ãƒƒãƒˆãƒ—ãƒ¬ã‚¤ã‚¹24ç·´é¦¬æ—©å®®<br></div>"
        
        self.logger.info(f"{removed_count}å€‹ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å‰Šé™¤ã—ã¾ã—ãŸ")
        return result_content

    def clean_memo_content_with_patterns(self, processed_patterns):
        """å‡¦ç†æ¸ˆã¿ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ä½¿ç”¨ã—ã¦ãƒ¡ãƒ¢ã‚’ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°"""
        self.logger.info("ğŸ§¹ ãƒ¡ãƒ¢ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°é–‹å§‹...")

        # ç¾åœ¨ã®ãƒ¡ãƒ¢å†…å®¹ã‚’å–å¾—
        memo_content = self.get_memo_content()
        if not memo_content:
            self.logger.error("ãƒ¡ãƒ¢å†…å®¹ã®å–å¾—ã«å¤±æ•—")
            return False

        # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ
        backup_file = self.backup_memo_content(memo_content)
        if not backup_file:
            self.logger.error("ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆã«å¤±æ•—")
            return False

        # å‡¦ç†æ¸ˆã¿ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒãªã„å ´åˆ
        if not processed_patterns:
            self.logger.info("å‰Šé™¤å¯¾è±¡ã®ãƒ‡ãƒ¼ã‚¿ã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            return True

        # æ–°ã—ã„ãƒ¡ãƒ¢å†…å®¹ã‚’ä½œæˆï¼ˆå‡¦ç†æ¸ˆã¿ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å‰Šé™¤ï¼‰
        new_content = self.clean_processed_patterns_from_memo(memo_content, processed_patterns)

        # ãƒ¡ãƒ¢ã‚’æ›´æ–°
        try:
            # ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—å‡¦ç†
            escaped_content = new_content.replace('"', '\\"').replace('\n', '\\n')
            script = f'''
            tell application "Notes"
                try
                    set targetNote to first note whose name contains "ãƒ•ã‚£ãƒƒãƒˆ"
                    set body of targetNote to "{escaped_content}"
                    return "âœ… ãƒ¡ãƒ¢ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°å®Œäº†"
                on error
                    return "âŒ ãƒ¡ãƒ¢æ›´æ–°ã‚¨ãƒ©ãƒ¼"
                end try
            end tell
            '''
            
            result = subprocess.run(
                ["osascript", "-e", script],
                capture_output=True,
                text=True,
                encoding="utf-8",
                timeout=15
            )
            
            if result.returncode == 0 and "âœ…" in result.stdout:
                self.logger.info("âœ… ãƒ¡ãƒ¢ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ãŒå®Œäº†ã—ã¾ã—ãŸ")
                return True
            else:
                self.logger.error(f"ãƒ¡ãƒ¢æ›´æ–°ã‚¨ãƒ©ãƒ¼: {result.stderr}")
                return False
                
        except Exception as e:
            self.logger.error(f"ãƒ¡ãƒ¢ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã‚¨ãƒ©ãƒ¼: {e}")
            return False

    def clean_memo_content(self, dry_run=False):
        """å‡¦ç†æ¸ˆã¿ãƒ¡ãƒ¢å†…å®¹ã‚’å‰Šé™¤"""
        self.logger.info("ğŸ§¹ ãƒ¡ãƒ¢ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°é–‹å§‹...")

        # ç¾åœ¨ã®ãƒ¡ãƒ¢å†…å®¹ã‚’å–å¾—
        memo_content = self.get_memo_content()
        if not memo_content:
            self.logger.error("ãƒ¡ãƒ¢å†…å®¹ã®å–å¾—ã«å¤±æ•—")
            return False

        # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ
        backup_file = self.backup_memo_content(memo_content)
        if not backup_file:
            self.logger.error("ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆã«å¤±æ•—")
            return False

        # å‰Šé™¤å¯¾è±¡ã‚’ç‰¹å®šï¼ˆæ˜¨æ—¥ä»¥å‰ã®ãƒ‡ãƒ¼ã‚¿ï¼‰
        cutoff_date = datetime.now().date()
        lines_to_remove = self.identify_processed_memo_content(
            memo_content, cutoff_date
        )

        if not lines_to_remove:
            self.logger.info("å‰Šé™¤å¯¾è±¡ã®ãƒ‡ãƒ¼ã‚¿ã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            return True

        if dry_run:
            self.logger.info(f"DRY RUN: {len(lines_to_remove)}è¡ŒãŒå‰Šé™¤å¯¾è±¡ã§ã™")
            return True

        # æ–°ã—ã„ãƒ¡ãƒ¢å†…å®¹ã‚’ä½œæˆ
        lines = memo_content.split("\n")
        new_lines = [line for i, line in enumerate(lines) if i not in lines_to_remove]
        new_content = "\n".join(new_lines)

        # ãƒ¡ãƒ¢ã‚’æ›´æ–°
        try:
            # f-stringã§ã®ãƒãƒƒã‚¯ã‚¹ãƒ©ãƒƒã‚·ãƒ¥ã‚¨ãƒ©ãƒ¼ã‚’å›é¿ã™ã‚‹ãŸã‚ã€äº‹å‰ã«å‡¦ç†
            escaped_content = new_content.replace('"', '\\"')
            script = f"""
            tell application "Notes"
                set body of note 1 to "{escaped_content}"
            end tell
            """

            result = subprocess.run(
                ["osascript", "-e", script],
                capture_output=True,
                text=True,
                encoding="utf-8",
            )

            if result.returncode == 0:
                self.logger.info(
                    f"âœ… ãƒ¡ãƒ¢ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°å®Œäº†: {len(lines_to_remove)}è¡Œå‰Šé™¤"
                )
                return True
            else:
                self.logger.error(f"ãƒ¡ãƒ¢æ›´æ–°ã‚¨ãƒ©ãƒ¼: {result.stderr}")
                return False

        except Exception as e:
            self.logger.error(f"ãƒ¡ãƒ¢ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã‚¨ãƒ©ãƒ¼: {e}")
            return False

    def analyze_data(self):
        """ãƒ‡ãƒ¼ã‚¿åˆ†æã‚’å®Ÿè¡Œ"""
        try:
            existing_data, _ = self.get_existing_csv_data()

            if not existing_data:
                self.logger.warning("åˆ†æå¯¾è±¡ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
                return

            # æ™‚é–“å¸¯åˆ¥åˆ†æ
            hourly_analysis = defaultdict(list)

            for row in existing_data:
                if row["hour"] and row["count"]:
                    hour = int(row["hour"])
                    count = int(row["count"])
                    hourly_analysis[hour].append(count)

            self.logger.info(f"ğŸ“Š ãƒ‡ãƒ¼ã‚¿åˆ†æçµæœï¼ˆç·ãƒ‡ãƒ¼ã‚¿æ•°: {len(existing_data)}ä»¶ï¼‰")

            # æœ€é©æ™‚é–“å¸¯ã®ç‰¹å®š
            best_times = []
            for hour in sorted(hourly_analysis.keys()):
                counts = hourly_analysis[hour]
                avg_count = sum(counts) / len(counts)
                if avg_count <= 15:
                    best_times.append((hour, avg_count))

            if best_times:
                best_times.sort(key=lambda x: x[1])
                self.logger.info("ğŸ¯ æœ€é©åˆ©ç”¨æ™‚é–“å¸¯ï¼ˆç©ºã„ã¦ã„ã‚‹æ™‚é–“å¸¯ï¼‰:")
                for hour, avg in best_times:
                    self.logger.info(f"  {hour:2d}:00 - å¹³å‡ {avg:.1f}äºº â­ï¸")

            # æ··é›‘æ™‚é–“å¸¯ã®ç‰¹å®š
            busy_times = []
            for hour in sorted(hourly_analysis.keys()):
                counts = hourly_analysis[hour]
                avg_count = sum(counts) / len(counts)
                if avg_count >= 20:
                    busy_times.append((hour, avg_count))

            if busy_times:
                busy_times.sort(key=lambda x: x[1], reverse=True)
                self.logger.info("âš ï¸  æ··é›‘æ™‚é–“å¸¯ï¼ˆé¿ã‘ã‚‹ã¹ãæ™‚é–“å¸¯ï¼‰:")
                for hour, avg in busy_times:
                    self.logger.info(f"  {hour:2d}:00 - å¹³å‡ {avg:.1f}äºº âš ï¸")

        except Exception as e:
            self.logger.error(f"åˆ†æã‚¨ãƒ©ãƒ¼: {e}")

    def run_weekly_automation(self, clean_memo=True):
        """é€±æ¬¡è‡ªå‹•å®Ÿè¡Œ"""
        self.logger.info("ğŸš€ é€±æ¬¡è‡ªå‹•å®Ÿè¡Œã‚’é–‹å§‹ã—ã¾ã™...")

        try:
            # 1. ãƒ¡ãƒ¢ã‹ã‚‰æ–°ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            self.logger.info("ğŸ“± ãƒ¡ãƒ¢ã‚¢ãƒ—ãƒªã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­...")
            memo_content = self.get_memo_content()
            if not memo_content:
                self.logger.error("âŒ ãƒ¡ãƒ¢ãƒ‡ãƒ¼ã‚¿ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ")
                return False

            # 2. æ··é›‘çŠ¶æ³ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºãƒ»æ§‹é€ åŒ–
            self.logger.info("ğŸ” æ··é›‘çŠ¶æ³ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºä¸­...")
            gym_data, processed_patterns = self.extract_gym_data(memo_content)
            self.logger.info(f"ğŸ“Š æ··é›‘çŠ¶æ³ãƒ‡ãƒ¼ã‚¿ã‚’ {len(gym_data)} ä»¶æŠ½å‡ºã—ã¾ã—ãŸ")

            # 3. CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›´æ–°
            self.logger.info("ğŸ’¾ CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›´æ–°ä¸­...")
            new_count, total_count = self.update_csv(gym_data)

            if new_count > 0:
                self.logger.info(f"âœ… {new_count} ä»¶ã®æ–°ãƒ‡ãƒ¼ã‚¿ã‚’CSVã«è¿½åŠ ã—ã¾ã—ãŸ")
            else:
                self.logger.info("â„¹ï¸  è¿½åŠ ã™ã‚‹æ–°ãƒ‡ãƒ¼ã‚¿ã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸ")

            self.logger.info(f"ğŸ“ ç·ãƒ‡ãƒ¼ã‚¿æ•°: {total_count} ä»¶")

            # 4. ãƒ¡ãƒ¢ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            if clean_memo:
                self.logger.info("ğŸ§¹ ãƒ¡ãƒ¢ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã‚’å®Ÿè¡Œä¸­...")
                clean_success = self.clean_memo_content_with_patterns(processed_patterns)
                if not clean_success:
                    self.logger.warning(
                        "âš ï¸  ãƒ¡ãƒ¢ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã«å¤±æ•—ã—ã¾ã—ãŸãŒã€å‡¦ç†ã‚’ç¶™ç¶šã—ã¾ã™"
                    )

            # 5. ãƒ‡ãƒ¼ã‚¿åˆ†æã‚’å®Ÿè¡Œ
            self.logger.info("ğŸ“Š ãƒ‡ãƒ¼ã‚¿åˆ†æã‚’å®Ÿè¡Œä¸­...")
            self.analyze_data()

            self.logger.info("ğŸ‰ é€±æ¬¡è‡ªå‹•å®Ÿè¡ŒãŒå®Œäº†ã—ã¾ã—ãŸï¼")
            return True

        except Exception as e:
            self.logger.error(f"é€±æ¬¡è‡ªå‹•å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
            return False

    def run_manual_mode(self):
        """æ‰‹å‹•å®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰"""
        self.logger.info("ğŸ¤– ã‚¸ãƒ æ··é›‘çŠ¶æ³ è‡ªå‹•åŒ–ã‚·ã‚¹ãƒ†ãƒ ")
        print("=" * 60)
        print("1. ğŸš€ é€šå¸¸ã®è‡ªå‹•åŒ–ã‚’å®Ÿè¡Œ")
        print("2. ğŸ“± ãƒ¡ãƒ¢å†…å®¹ã‚’ç¢ºèª")
        print("3. ğŸ§¹ ãƒ¡ãƒ¢ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³ï¼‰")
        print("4. ğŸ§¹ ãƒ¡ãƒ¢ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆå®Ÿè¡Œï¼‰")
        print("5. ğŸ“Š åˆ†æã®ã¿å®Ÿè¡Œ")
        print("6. ğŸ”„ é€±æ¬¡è‡ªå‹•å®Ÿè¡Œï¼ˆãƒ•ãƒ«æ©Ÿèƒ½ï¼‰")

        choice = input("\né¸æŠã—ã¦ãã ã•ã„ (1-6): ")

        if choice == "1":
            # é€šå¸¸ã®è‡ªå‹•åŒ–å®Ÿè¡Œï¼ˆã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ãªã—ï¼‰
            self.run_weekly_automation(clean_memo=False)
        elif choice == "2":
            memo_content = self.get_memo_content()
            if memo_content:
                print("ğŸ“± ãƒ¡ãƒ¢å†…å®¹ï¼ˆæœ€æ–°1000æ–‡å­—ï¼‰:")
                print("=" * 50)
                print(memo_content[-1000:])
                print("=" * 50)
        elif choice == "3":
            # ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³
            self.clean_memo_content(dry_run=True)
        elif choice == "4":
            # å®Ÿéš›ã®ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
            self.clean_memo_content(dry_run=False)
        elif choice == "5":
            self.analyze_data()
        elif choice == "6":
            # ãƒ•ãƒ«é€±æ¬¡è‡ªå‹•å®Ÿè¡Œ
            self.run_weekly_automation(clean_memo=True)
        else:
            print("âŒ ç„¡åŠ¹ãªé¸æŠã§ã™")


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    automation = GymAnalysisAutomation()

    # å¼•æ•°ãƒã‚§ãƒƒã‚¯ï¼ˆè‡ªå‹•å®Ÿè¡Œç”¨ï¼‰
    import sys

    if len(sys.argv) > 1 and sys.argv[1] == "--weekly":
        # é€±æ¬¡è‡ªå‹•å®Ÿè¡Œ
        automation.run_weekly_automation(clean_memo=True)
    else:
        # æ‰‹å‹•å®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰
        automation.run_manual_mode()


if __name__ == "__main__":
    main()
