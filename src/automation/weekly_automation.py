#!/usr/bin/env python3
"""
ã‚¸ãƒ æ··é›‘çŠ¶æ³ å®Œå…¨è‡ªå‹•åŒ–ã‚·ã‚¹ãƒ†ãƒ ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«ãƒ™ãƒ¼ã‚¹ç‰ˆï¼‰
- Apple ãƒ¡ãƒ¢ã‚’ä½¿ã‚ãªã„å®‰å®šã‚·ã‚¹ãƒ†ãƒ 
- iCloudãƒ•ã‚¡ã‚¤ãƒ«ç›´æ¥å‡¦ç†
- å®Œå…¨ãªãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ä¿è¨¼
"""

import csv
import json
import re
import os
import shutil
import datetime as dt
from pathlib import Path
import logging
from collections import defaultdict


class GymAnalysisAutomation:
    def __init__(self):
        self.project_dir = Path("/Users/i_kawano/Documents/training_waitnum_analysis")
        self.csv_file = self.project_dir / "data" / "fit_place24_data.csv"
        self.backup_dir = self.project_dir / "backups"
        self.log_file = self.project_dir / "logs" / "automation.log"
        
        # iCloudãƒ‘ã‚¹è¨­å®š
        self.icloud_base = Path.home() / "Library/Mobile Documents/com~apple~CloudDocs/Shortcuts/FIT_PLACE24"
        self.inbox_file = self.icloud_base / "inbox.csv"
        
        # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãƒãƒƒãƒ”ãƒ³ã‚°
        self.status_map = {
            "ç©ºã„ã¦ã„ã¾ã™": "low",
            "ã‚„ã‚„ç©ºã„ã¦ã„ã¾ã™": "mid-low", 
            "æ™®é€š": "mid",
            "ã‚„ã‚„æ··é›‘": "mid-high",
            "ã‚„ã‚„æ··ã‚“ã§ã„ã¾ã™": "mid-high",
            "æ··é›‘": "high",
            "æ··ã‚“ã§ã„ã¾ã™": "high",
            "ã‹ãªã‚Šæ··é›‘": "very-high",
        }
        
        self._setup_directories()
        self._setup_logging()

    def _setup_directories(self):
        """å¿…è¦ãªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ"""
        self.backup_dir.mkdir(parents=True, exist_ok=True)
        self.csv_file.parent.mkdir(parents=True, exist_ok=True)
        self.log_file.parent.mkdir(parents=True, exist_ok=True)
        self.icloud_base.mkdir(parents=True, exist_ok=True)

    def _setup_logging(self):
        """ãƒ­ã‚°è¨­å®š"""
        logging.basicConfig(
            level=logging.INFO,
            format="%(asctime)s - %(levelname)s - %(message)s",
            handlers=[
                logging.FileHandler(self.log_file, encoding="utf-8"),
                logging.StreamHandler(),
            ],
        )
        self.logger = logging.getLogger(__name__)

    def read_existing_csv_data(self):
        """æ—¢å­˜ã®CSVãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿"""
        existing_data = []
        existing_keys = set()
        
        if self.csv_file.exists():
            try:
                with self.csv_file.open(newline="", encoding="utf-8") as f:
                    reader = csv.DictReader(f)
                    for row in reader:
                        existing_data.append(row)
                        # é‡è¤‡ãƒã‚§ãƒƒã‚¯ç”¨ã‚­ãƒ¼ï¼ˆæ—¥æ™‚+å ´æ‰€+äººæ•°ï¼‰
                        key = (row.get("datetime", ""), row.get("location", ""), str(row.get("count", "")))
                        existing_keys.add(key)
            except Exception as e:
                self.logger.error(f"æ—¢å­˜CSVèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        
        return existing_data, existing_keys

    def read_inbox_csv(self):
        """inbox.csvã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿"""
        if not self.inbox_file.exists():
            self.logger.info("inbox.csvãŒå­˜åœ¨ã—ã¾ã›ã‚“")
            return []
        
        try:
            with self.inbox_file.open("r", encoding="utf-8", newline="") as f:
                reader = csv.reader(f)
                rows = []
                
                for line_num, row in enumerate(reader, 1):
                    if len(row) < 7:
                        self.logger.warning(f"inbox.csv è¡Œ{line_num}: ã‚«ãƒ©ãƒ ä¸è¶³ ({len(row)}/7)")
                        continue
                    
                    source, ts_local, people, status, location, device, raw = row[:7]
                    
                    # ãƒ‡ãƒ¼ã‚¿æ­£è¦åŒ–
                    people_num = None
                    if people:
                        match = re.search(r"(\d{1,3})", people)
                        if match:
                            people_num = int(match.group(1))
                    
                    # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹æ­£è¦åŒ–
                    normalized_status = self.status_map.get(status, status or "")
                    
                    processed_row = {
                        "source": source,
                        "ts_local": ts_local,
                        "people": people_num if people_num is not None else "",
                        "status": normalized_status,
                        "location": location,
                        "device": device,
                        "raw": raw,
                        "line_num": line_num
                    }
                    rows.append(processed_row)
                
                self.logger.info(f"inbox.csvã‹ã‚‰{len(rows)}ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿")
                return rows
                
        except Exception as e:
            self.logger.error(f"inbox.csvèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return []

    def convert_to_dashboard_format(self, inbox_data):
        """inbox.csvãƒ‡ãƒ¼ã‚¿ã‚’ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰å½¢å¼ã«å¤‰æ›"""
        converted_data = []
        
        for row in inbox_data:
            try:
                # æ—¥æ™‚è§£æ
                ts_str = row["ts_local"]
                if not ts_str:
                    continue
                
                # ISO 8601å½¢å¼ã‚’ãƒ‘ãƒ¼ã‚¹
                try:
                    dt_obj = dt.datetime.fromisoformat(ts_str.replace('Z', '+00:00'))
                except ValueError:
                    # åˆ¥ã®å½¢å¼ã‚’è©¦è¡Œ
                    dt_obj = dt.datetime.strptime(ts_str, "%Y-%m-%d %H:%M:%S")
                
                # ã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³ã‚’çµ±ä¸€ï¼ˆnaive datetimeã«å¤‰æ›ï¼‰
                if dt_obj.tzinfo is not None:
                    dt_obj = dt_obj.replace(tzinfo=None)
                
                # æœªæ¥ã®ãƒ‡ãƒ¼ã‚¿ã‚’æ‹’å¦
                now = dt.datetime.now()
                if dt_obj > now:
                    dt_obj = dt_obj - dt.timedelta(days=1)
                    self.logger.info(f"æœªæ¥æ™‚åˆ»ã‚’æ˜¨æ—¥ã®ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦è§£é‡ˆ: {dt_obj}")
                
                # å¤ã™ãã‚‹ãƒ‡ãƒ¼ã‚¿ã‚’æ‹’å¦ï¼ˆ7æ—¥ä»¥ä¸Šå‰ï¼‰
                if (now - dt_obj).days > 7:
                    self.logger.warning(f"å¤ã™ãã‚‹ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¹ã‚­ãƒƒãƒ—: {dt_obj}")
                    continue
                
                people = row["people"]
                if not isinstance(people, int):
                    continue
                
                # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹æƒ…å ±ã‚’ç”Ÿæˆ
                status_info = self._generate_status_info(people, row["status"])
                
                converted_row = {
                    "datetime": dt_obj.strftime("%Y-%m-%d %H:%M:%S"),
                    "date": dt_obj.strftime("%Y-%m-%d"),
                    "time": dt_obj.strftime("%H:%M"),
                    "hour": dt_obj.hour,
                    "weekday": dt_obj.strftime("%A"),
                    "count": people,
                    "status_label": status_info["label"],
                    "status_code": status_info["code"],
                    "status_min": status_info["min"],
                    "status_max": status_info["max"],
                    "raw_text": row["raw"],
                }
                
                converted_data.append(converted_row)
                
            except Exception as e:
                self.logger.warning(f"ãƒ‡ãƒ¼ã‚¿å¤‰æ›ã‚¨ãƒ©ãƒ¼ (è¡Œ{row.get('line_num', '?')}): {e}")
                continue
        
        self.logger.info(f"{len(converted_data)}ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’å¤‰æ›å®Œäº†")
        return converted_data

    def _generate_status_info(self, people_count, status_text):
        """äººæ•°ã¨ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰è©³ç´°ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹æƒ…å ±ã‚’ç”Ÿæˆ"""
        # ãƒ†ã‚­ã‚¹ãƒˆãƒ™ãƒ¼ã‚¹ã®åˆ¤å®š
        if "ç©ºã„ã¦ã„ã¾ã™" in status_text and "ã‚„ã‚„" not in status_text:
            return {"code": 5, "label": "ç©ºã„ã¦ã„ã¾ã™ï¼ˆ~10äººï¼‰", "min": 0, "max": 10}
        elif "ã‚„ã‚„ç©ºã„ã¦ã„ã¾ã™" in status_text:
            return {"code": 4, "label": "ã‚„ã‚„ç©ºã„ã¦ã„ã¾ã™ï¼ˆ~20äººï¼‰", "min": 11, "max": 20}
        elif "ã‚„ã‚„æ··ã‚“ã§ã„ã¾ã™" in status_text or "ã‚„ã‚„æ··é›‘" in status_text:
            return {"code": 3, "label": "å°‘ã—æ··ã‚“ã§ã„ã¾ã™ï¼ˆ~30äººï¼‰", "min": 21, "max": 30}
        elif "æ··ã‚“ã§ã„ã¾ã™" in status_text or "æ··é›‘" in status_text:
            return {"code": 2, "label": "æ··ã‚“ã§ã„ã¾ã™ï¼ˆ~40äººï¼‰", "min": 31, "max": 40}
        else:
            # äººæ•°ãƒ™ãƒ¼ã‚¹ã®åˆ¤å®š
            if people_count <= 10:
                return {"code": 5, "label": "ç©ºã„ã¦ã„ã¾ã™ï¼ˆ~10äººï¼‰", "min": 0, "max": 10}
            elif people_count <= 20:
                return {"code": 4, "label": "ã‚„ã‚„ç©ºã„ã¦ã„ã¾ã™ï¼ˆ~20äººï¼‰", "min": 11, "max": 20}
            elif people_count <= 30:
                return {"code": 3, "label": "å°‘ã—æ··ã‚“ã§ã„ã¾ã™ï¼ˆ~30äººï¼‰", "min": 21, "max": 30}
            else:
                return {"code": 2, "label": "æ··ã‚“ã§ã„ã¾ã™ï¼ˆ~40äººï¼‰", "min": 31, "max": 40}

    def dedupe_data(self, all_data):
        """é‡è¤‡ãƒ‡ãƒ¼ã‚¿ã‚’é™¤å»"""
        seen = set()
        unique_data = []
        
        for row in sorted(all_data, key=lambda x: x.get("datetime", "")):
            # é‡è¤‡ãƒã‚§ãƒƒã‚¯ã‚­ãƒ¼
            key = (row.get("datetime", ""), row.get("location", "çŸ¢å‘"), str(row.get("count", "")))
            
            if key in seen:
                self.logger.debug(f"é‡è¤‡ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¹ã‚­ãƒƒãƒ—: {key}")
                continue
            
            seen.add(key)
            unique_data.append(row)
        
        removed = len(all_data) - len(unique_data)
        if removed > 0:
            self.logger.info(f"é‡è¤‡ãƒ‡ãƒ¼ã‚¿{removed}ä»¶ã‚’é™¤å»")
        
        return unique_data

    def write_csv(self, data):
        """CSVãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãè¾¼ã¿"""
        fieldnames = [
            "datetime", "date", "time", "hour", "weekday",
            "count", "status_label", "status_code", "status_min", "status_max", "raw_text"
        ]
        
        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãè¾¼ã¿å¾Œã€ã‚¢ãƒˆãƒŸãƒƒã‚¯ç§»å‹•
        tmp_file = self.csv_file.with_suffix(".tmp.csv")
        
        try:
            with tmp_file.open("w", encoding="utf-8", newline="") as f:
                writer = csv.DictWriter(f, fieldnames=fieldnames)
                writer.writeheader()
                
                for row in data:
                    # ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰åã«åˆã‚ã›ã¦ãƒ‡ãƒ¼ã‚¿ã‚’æ•´ç†
                    clean_row = {field: row.get(field, "") for field in fieldnames}
                    writer.writerow(clean_row)
            
            # ã‚¢ãƒˆãƒŸãƒƒã‚¯ç§»å‹•
            shutil.move(str(tmp_file), str(self.csv_file))
            self.logger.info(f"CSVãƒ•ã‚¡ã‚¤ãƒ«æ›´æ–°å®Œäº†: {len(data)}ä»¶")
            return True
            
        except Exception as e:
            if tmp_file.exists():
                tmp_file.unlink()
            self.logger.error(f"CSVæ›¸ãè¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return False

    def backup_inbox(self):
        """å‡¦ç†æ¸ˆã¿inbox.csvã‚’ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—"""
        if not self.inbox_file.exists():
            return True
        
        timestamp = dt.datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_path = self.backup_dir / f"inbox_{timestamp}.csv"
        
        try:
            shutil.move(str(self.inbox_file), str(backup_path))
            self.logger.info(f"inbox.csvã‚’ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—: {backup_path.name}")
            return True
        except Exception as e:
            self.logger.error(f"inboxãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼: {e}")
            return False

    def analyze_data(self):
        """ãƒ‡ãƒ¼ã‚¿åˆ†æã‚’å®Ÿè¡Œ"""
        try:
            existing_data, _ = self.read_existing_csv_data()
            
            if not existing_data:
                self.logger.warning("åˆ†æå¯¾è±¡ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
                return
            
            # æ™‚é–“å¸¯åˆ¥åˆ†æ
            hourly_analysis = defaultdict(list)
            
            for row in existing_data:
                if row.get("hour") and row.get("count"):
                    try:
                        hour = int(row["hour"])
                        count = int(row["count"])
                        hourly_analysis[hour].append(count)
                    except ValueError:
                        continue
            
            self.logger.info(f"ğŸ“Š ãƒ‡ãƒ¼ã‚¿åˆ†æçµæœï¼ˆç·ãƒ‡ãƒ¼ã‚¿æ•°: {len(existing_data)}ä»¶ï¼‰")
            
            # æœ€é©æ™‚é–“å¸¯
            best_times = []
            for hour in sorted(hourly_analysis.keys()):
                counts = hourly_analysis[hour]
                avg_count = sum(counts) / len(counts)
                if avg_count <= 15:
                    best_times.append((hour, avg_count))
            
            if best_times:
                best_times.sort(key=lambda x: x[1])
                self.logger.info("ğŸ¯ æœ€é©åˆ©ç”¨æ™‚é–“å¸¯ï¼ˆç©ºã„ã¦ã„ã‚‹æ™‚é–“å¸¯ï¼‰:")
                for hour, avg in best_times:
                    self.logger.info(f"  {hour:2d}:00 - å¹³å‡ {avg:.1f}äºº â­ï¸")
            
            # æ··é›‘æ™‚é–“å¸¯
            busy_times = []
            for hour in sorted(hourly_analysis.keys()):
                counts = hourly_analysis[hour]
                avg_count = sum(counts) / len(counts)
                if avg_count >= 20:
                    busy_times.append((hour, avg_count))
            
            if busy_times:
                busy_times.sort(key=lambda x: x[1], reverse=True)
                self.logger.info("âš ï¸ æ··é›‘æ™‚é–“å¸¯ï¼ˆé¿ã‘ã‚‹ã¹ãæ™‚é–“å¸¯ï¼‰:")
                for hour, avg in busy_times:
                    self.logger.info(f"  {hour:2d}:00 - å¹³å‡ {avg:.1f}äºº âš ï¸")
                    
        except Exception as e:
            self.logger.error(f"åˆ†æã‚¨ãƒ©ãƒ¼: {e}")

    def run_weekly_automation(self):
        """é€±æ¬¡è‡ªå‹•å®Ÿè¡Œï¼ˆãƒ¡ã‚¤ãƒ³å‡¦ç†ï¼‰"""
        self.logger.info("ğŸš€ é€±æ¬¡è‡ªå‹•å®Ÿè¡Œã‚’é–‹å§‹ã—ã¾ã™...")
        
        try:
            # 1. inbox.csvã‹ã‚‰æ–°ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
            self.logger.info("ğŸ“‚ inbox.csvã‹ã‚‰æ–°ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ä¸­...")
            inbox_data = self.read_inbox_csv()
            
            if not inbox_data:
                self.logger.info("ğŸ“‹ æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
                return True
            
            # 2. ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰å½¢å¼ã«å¤‰æ›
            self.logger.info("ğŸ”„ ãƒ‡ãƒ¼ã‚¿ã‚’å¤‰æ›ä¸­...")
            converted_data = self.convert_to_dashboard_format(inbox_data)
            
            if not converted_data:
                self.logger.warning("âš ï¸ å¤‰æ›å¯èƒ½ãªãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
                self.backup_inbox()  # ç©ºã§ã‚‚ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
                return True
            
            # 3. æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã¨çµ±åˆ
            self.logger.info("ğŸ”— æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã¨çµ±åˆä¸­...")
            existing_data, _ = self.read_existing_csv_data()
            all_data = existing_data + converted_data
            
            # 4. é‡è¤‡é™¤å»
            unique_data = self.dedupe_data(all_data)
            
            # 5. CSVãƒ•ã‚¡ã‚¤ãƒ«æ›´æ–°
            self.logger.info("ğŸ’¾ CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›´æ–°ä¸­...")
            if not self.write_csv(unique_data):
                self.logger.error("âŒ CSVæ›´æ–°ã«å¤±æ•—")
                return False
            
            new_count = len(converted_data)
            total_count = len(unique_data)
            
            self.logger.info(f"âœ… {new_count}ä»¶ã®æ–°ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ ")
            self.logger.info(f"ğŸ“ ç·ãƒ‡ãƒ¼ã‚¿æ•°: {total_count}ä»¶")
            
            # 6. inbox.csvã‚’ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
            self.logger.info("ğŸ—ƒï¸ inbox.csvã‚’ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä¸­...")
            if not self.backup_inbox():
                self.logger.warning("âš ï¸ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã«å¤±æ•—ã—ã¾ã—ãŸãŒã€å‡¦ç†ã‚’ç¶™ç¶š")
            
            # 7. ãƒ‡ãƒ¼ã‚¿åˆ†æ
            self.logger.info("ğŸ“Š ãƒ‡ãƒ¼ã‚¿åˆ†æã‚’å®Ÿè¡Œä¸­...")
            self.analyze_data()
            
            self.logger.info("ğŸ‰ é€±æ¬¡è‡ªå‹•å®Ÿè¡ŒãŒå®Œäº†ã—ã¾ã—ãŸï¼")
            return True
            
        except Exception as e:
            self.logger.error(f"é€±æ¬¡è‡ªå‹•å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
            return False

    def diagnose_system(self):
        """ã‚·ã‚¹ãƒ†ãƒ è¨ºæ–­"""
        self.logger.info("ğŸ” ã‚·ã‚¹ãƒ†ãƒ è¨ºæ–­ã‚’é–‹å§‹...")
        
        # iCloudãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ç¢ºèª
        if not self.icloud_base.exists():
            self.logger.error(f"âŒ iCloudãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ã¾ã›ã‚“: {self.icloud_base}")
            return False
        
        # inbox.csvã®ç¢ºèª
        if self.inbox_file.exists():
            try:
                with self.inbox_file.open("r", encoding="utf-8") as f:
                    lines = f.readlines()
                self.logger.info(f"ğŸ“‚ inbox.csv: {len(lines)}è¡Œã®ãƒ‡ãƒ¼ã‚¿")
            except Exception as e:
                self.logger.error(f"âŒ inbox.csvèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        else:
            self.logger.info("ğŸ“‚ inbox.csv: ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“")
        
        # æ—¢å­˜CSVã®ç¢ºèª
        if self.csv_file.exists():
            existing_data, _ = self.read_existing_csv_data()
            self.logger.info(f"ğŸ’¾ æ—¢å­˜CSV: {len(existing_data)}ä»¶ã®ãƒ‡ãƒ¼ã‚¿")
        else:
            self.logger.info("ğŸ’¾ æ—¢å­˜CSV: ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“")
        
        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ¨©é™ã®ç¢ºèª
        for path in [self.icloud_base, self.backup_dir, self.csv_file.parent]:
            if path.exists() and os.access(path, os.R_OK | os.W_OK):
                self.logger.info(f"âœ… {path.name}: èª­ã¿æ›¸ãæ¨©é™OK")
            else:
                self.logger.warning(f"âš ï¸ {path.name}: æ¨©é™ä¸è¶³ã¾ãŸã¯å­˜åœ¨ã—ãªã„")
        
        self.logger.info("ğŸ” ã‚·ã‚¹ãƒ†ãƒ è¨ºæ–­å®Œäº†")
        return True

    def create_sample_inbox(self):
        """ãƒ†ã‚¹ãƒˆç”¨ã®ã‚µãƒ³ãƒ—ãƒ«inbox.csvã‚’ä½œæˆ"""
        sample_data = [
            ["FIT_PLACE24", "2025-08-15T19:30:00+09:00", "20", "ã‚„ã‚„ç©ºã„ã¦ã„ã¾ã™", "çŸ¢å‘", "iPhone", "æ··é›‘çŠ¶æ³ 20äºº ã‚„ã‚„ç©ºã„ã¦ã„ã¾ã™"],
            ["FIT_PLACE24", "2025-08-15T14:15:00+09:00", "15", "ç©ºã„ã¦ã„ã¾ã™", "çŸ¢å‘", "iPhone", "æ··é›‘çŠ¶æ³ 15äºº ç©ºã„ã¦ã„ã¾ã™"],
        ]
        
        try:
            with self.inbox_file.open("w", encoding="utf-8", newline="") as f:
                writer = csv.writer(f)
                writer.writerows(sample_data)
            self.logger.info(f"ğŸ“ ã‚µãƒ³ãƒ—ãƒ«inbox.csvã‚’ä½œæˆ: {self.inbox_file}")
            return True
        except Exception as e:
            self.logger.error(f"ã‚µãƒ³ãƒ—ãƒ«ä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
            return False


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    automation = GymAnalysisAutomation()
    
    import sys
    
    if len(sys.argv) > 1:
        command = sys.argv[1]
        if command == "--weekly":
            automation.run_weekly_automation()
        elif command == "diagnose":
            automation.diagnose_system()
        elif command == "analyze":
            automation.analyze_data()
        elif command == "sample":
            automation.create_sample_inbox()
        else:
            print(f"âŒ ä¸æ˜ãªã‚³ãƒãƒ³ãƒ‰: {command}")
            print("åˆ©ç”¨å¯èƒ½ãªã‚³ãƒãƒ³ãƒ‰: --weekly, diagnose, analyze, sample")
    else:
        # ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãƒ¢ãƒ¼ãƒ‰
        print("ğŸ¤– ã‚¸ãƒ æ··é›‘çŠ¶æ³ è‡ªå‹•åŒ–ã‚·ã‚¹ãƒ†ãƒ ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«ãƒ™ãƒ¼ã‚¹ç‰ˆï¼‰")
        print("=" * 60)
        print("1. ğŸš€ é€±æ¬¡è‡ªå‹•å®Ÿè¡Œ")
        print("2. ğŸ” ã‚·ã‚¹ãƒ†ãƒ è¨ºæ–­")
        print("3. ğŸ“Š ãƒ‡ãƒ¼ã‚¿åˆ†æã®ã¿")
        print("4. ğŸ“ ã‚µãƒ³ãƒ—ãƒ«inbox.csvä½œæˆ")
        
        choice = input("\né¸æŠã—ã¦ãã ã•ã„ (1-4): ")
        
        if choice == "1":
            automation.run_weekly_automation()
        elif choice == "2":
            automation.diagnose_system()
        elif choice == "3":
            automation.analyze_data()
        elif choice == "4":
            automation.create_sample_inbox()
        else:
            print("âŒ ç„¡åŠ¹ãªé¸æŠã§ã™")


if __name__ == "__main__":
    main()